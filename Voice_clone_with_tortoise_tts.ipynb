{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJySZpdK3bGHaOi7Rko8Sa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/workshops/blob/main/Voice_clone_with_tortoise_tts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üê∞ Voice cloning using {Tortoise-TTS}\n",
        "- The speech of deepfakes\n",
        "* Original code source [neonbjb/tortoise-tts](https://github.com/neonbjb/tortoise-tts)\n",
        "+ Use this tool responsibly!"
      ],
      "metadata": {
        "id": "tVxfALmHQafF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JrK20I32grP6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown üö©**Step 1.** Install {scipy}, {tortoise-tts}, {transformers}  \n",
        "\n",
        "#@markdown The installation may take a couple of minutes.\n",
        "# the scipy version packaged with colab is not tolerant of misformated WAV files.\n",
        "# install the latest version.\n",
        "\n",
        "%%capture\n",
        "!pip3 install -U scipy\n",
        "\n",
        "!git clone https://github.com/jnordberg/tortoise-tts.git\n",
        "\n",
        "# Changing current working directory to 'tortoise-tts' (from git clone)\n",
        "%cd tortoise-tts\n",
        "!pip3 install transformers==4.19.0\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gen09NM4hONQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656,
          "referenced_widgets": [
            "e08f28b949734597a0b0ffecea2c38ef",
            "f9e9fbf13f364e5a853a96b8c9bf5feb",
            "c384d5db93ee48c1a46b1fb91670f698",
            "a9c29cebd046481780d3b34344faa1c6",
            "168b45282bee47d1a06a68213fadb41b",
            "cc6c278904fb425da8b6487b47894537",
            "a5147d0701b5434dadbcf2475c62e4ae",
            "67281ddfaf68476082f9d0932ddfee2a",
            "10a259c1a00348aeabf7b33a889f5837",
            "4bb7c2a745b7411583582a7e30e85f4e",
            "0663304c3ae34c5c81086aaefa21ccaf",
            "57902836adc04ebe8285795971cf03d6",
            "0f174d887a5440cb8ac48535620447cb",
            "df2e14de1126436b8a3a37f49db79d30",
            "afd95246b9e543afb7ccb7ddb9ca390b",
            "ad97cb55a7484ee99ad1d7a3cc4907da",
            "6b9de7b699cc4655b73e30268c1927fe",
            "c30ff9be57c64ce6aa81d9c594e99e7b",
            "d257b8f6dee8427da3a4741e43efb77d",
            "0338c56128f14e5a9d81b7f32218cfa1",
            "e23bc91254274b8280ca45605b18b3e2",
            "c8008f0def4649d38e6057acfcd10721",
            "c6dedabd01d340b0ad89583849a1a1e1",
            "c814568293b94c76956dc23b67f776fe",
            "320b597550d04086a13c4c29c56d750a",
            "b042d2052928466abf97f5bf751b418f",
            "03a583f5be8b44b7bbda28b8333acaad",
            "fa4c833f407248638ba314d409e4aa60",
            "b64710812a1949ee87648b8fd004d54c",
            "b0a8efd1c0ea4ed2ab56c61fdc07ad75",
            "4717619b3a01472193f2073bc70575fe",
            "6040fcae73d74213ae3e66f996064f55",
            "6b0fb97e0a6a4acf91919147775e8181",
            "fa157a993b144c90b29445619728003a",
            "4d708ebf3d814beb9ef190067c8814f1",
            "415f15109f454592ae4c64ac99142a3c",
            "b393264e51484908a118651d2cd3e421",
            "d3b0cae339c84f7382eba4cc7282ad3c",
            "d4d04739350c41c39204e717f3fe6519",
            "8ae69b5529764cb9b533897f4f9bff8d",
            "15e6aac33be14b58a374c6837c0f7bae",
            "9ceac3405abf4adab5d40b3fb40242e8",
            "21cc79bba1794ccb9fd65e723066d2b8",
            "b98101e8e69649ee8a6f519f0ad7a844",
            "b0f7472fee454119b91bba38dc380ccb",
            "d4ea972e0f604318b32fb430e11a80a3",
            "29d527f29c454dd78b5700dd044c8eed",
            "9dfc93a824e343f1b4fa86b3cad242ef",
            "7d909a73b97043d19d3fc0b80e749b56",
            "3a8e41cc9fb5491aa49d866538e51dc9",
            "e20cd8be20404296817d94d65593d112",
            "7cdc580ddfe94665927a3b5cac5b6856",
            "a7b774a964104345b53f7a1b681c162f",
            "0f371b6b21a8495db10ec71e88cdc235",
            "4896aeb1c3e74f84a7444ee03e17b8e1",
            "ad49587eb95a44e18d02c72db7217030",
            "18a5d44b47814323a4a40ff5a93ed84d",
            "645f0dbbec8c4a249d927b417713abe1",
            "e24a6ee322e245c5b29da48d96825f2e",
            "e943ae092a1f4abeb4c982789b1a75a1",
            "95e17c291de64044a742856347d661d9",
            "3c4f777bf8cd4181b9ac478de1a073a8",
            "bfbee435847945af838e44527bb344af",
            "8bd12a4c53b54857a6e017301c2637c3",
            "c3b9ce8097bd4309b2bbff7ac344ca1f",
            "aefe9c1455fe42e98c170c6f94ac855d"
          ]
        },
        "outputId": "f539db94-66e6-430b-ccfb-cb72ea973ea3",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e08f28b949734597a0b0ffecea2c38ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57902836adc04ebe8285795971cf03d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6dedabd01d340b0ad89583849a1a1e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa157a993b144c90b29445619728003a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f7472fee454119b91bba38dc380ccb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad49587eb95a44e18d02c72db7217030"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading autoregressive.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading classifier.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/classifier.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading clvp2.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/clvp2.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading cvvp.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/cvvp.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading diffusion_decoder.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/diffusion_decoder.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading vocoder.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/vocoder.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading rlg_auto.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/rlg_auto.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Downloading rlg_diffuser.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/rlg_diffuser.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#@markdown üö© Step 2. Import packages, load models used by Tortoise from the HuggingFace \n",
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
        "\n",
        "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
        "tts = TextToSpeech()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown üö© Step 3. Type text to create with the voice clone. (Try one or two sentences as it takes some time to process.)\n",
        "# This is the text that will be spoken.\n",
        "\n",
        "text = input(\"Type text to create with your voice: \")\n",
        "\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "\n",
        "preset_mode = \"fast\" #@param = [\"fast\", \"ultra_fast\", \"standard\", \"high-quality\"]\n",
        "\n",
        "preset = preset_mode\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tH0-ya1LQMEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown üö© Step 4. Upload your file:\n",
        "\n",
        "#@markdown **Note:** Upload at least 2 audio files. They must be in wav format, 6 to 10 seconds long.\n",
        "# Optionally, upload use your own voice by running the next two cells. I recommend\n",
        "# you upload at least 2 audio clips. They must be a WAV file, 6-10 seconds long.\n",
        "CUSTOM_VOICE_NAME = \"martin\"\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
        "os.makedirs(custom_voice_folder)\n",
        "for i, file_data in enumerate(files.upload().values()):\n",
        "  with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "    f.write(file_data)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yx3PlJA9QMhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown üíé Generate speech: voice clone\n",
        "# Generate speech with the custotm voice.\n",
        "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, \n",
        "                          preset=preset)\n",
        "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 24000)\n",
        "IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YK97rDWjQPJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}